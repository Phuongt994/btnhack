<p dir="ltr"><span>The moniker &lsquo;deep learning&rsquo; floats around the media these days in the same casually understood and ill-explained manner as &lsquo;gluten&rsquo; and &lsquo;Donald Trump&rsquo;. This is simply a </span><span>neural network AI approach</span><span> that uses many layers of simulated neurons whose connection strengths change with experience, so that activation patterns that result from tens to potentially millions of neurons talking to one another in the network are adaptable. However, how the deep learning network achieves the answer it does is a bit of a black box. Understanding its operation is almost as hard as </span><span>peering into a biological brain</span><span>. </span></p>
<p dir="ltr"><span><span><img src="asset/photos/exmachina_cmyk.jpg" hspace="300" alt="" /></span></span></p>
<p dir="ltr">&nbsp;</p>
<p><em><span style="font-size: x-small;"><strong>Nathan:</strong> One day the AIs are going to look back on us the same way we look at fossil skeletons on the plains of Africa. An upright ape living in dust with crude language and tools, all set for extinction.</span></em></p>
<p dir="ltr"><span>Deep learning is a field that has received massive enthusiasm over the past few years, partly fed by increasing computing power that has helped chunk the data it handles into parallel streams. The brain does this to compute incoming sensory information, but the information it deals with compared to what we mostly use deep learning algorithms for it very different. A deep learning AI might easily chug through a sea of information on NHS trust performances in different parts of the country by sifting through individual patient outcome data on thousand of people in a few minutes, that is not something that is possible for you or I to achieve in weeks. But it can do so using a similar process to what we employ to make sense of incoming information from our eyes, ears, nose, skin and other sensory detectors. It compresses cluttered information from a high dimensionality space, to an understandable low dimensionality one. In other words, it captures the important information and does away with the rest. If your brain did not do that, your senses would overload your every waking moment. </span></p>
<p dir="ltr"><span><span>&nbsp;</span></span></p>
<p dir="ltr"><span>Google&rsquo;s DeepDream hit the headlines recently, largely for their ability to find and morph together random animals from features in any image a user feeds it. It employed a deep neural network built on the same principles as the visual processing areas in a human brain, effectively a </span><span>perceptron </span><span>with many layers of neurons. The weird animal images are generated when a network &lsquo;dreams&rsquo; on an image, processing it iteratively when there are not actual animals to find, and making them up. A bit like how you might extract sheep and faces and horses and angels in clouds on a nice afternoon. Such a &lsquo;convolutional&rsquo;, deep neural network was used by DeepMind&rsquo;s AlphaGo to try new moves, and evaluate the success of old ones. It is also used by DreamScope, an app that uses this biologically inspired image processing method to make photographs look like paintings, aping the styles of vsn Gogh and Picasso for example. We have used in photographs to generate many of the images you see with this content. (Also, it seems like ever since the success of </span><span>DeepBlue</span><span>, people in the AI field cannot resist using the adjective &lsquo;deep&rsquo; in naming their creations.)</span></p>
<p dir="ltr"><span><span><img src="asset/photos/4713e821-1ed4-46f5-8bd8-ff43252dc22e.jpeg" hspace="200" alt="" /></span></span></p>
<p dir="ltr"><span>But the raw power difference between a human and deep learning intelligence (the former of which has only 20 watts of power, the amount used for a dim light bulb, the latter of which could light an entire building) allowed DeepMind&rsquo;s AlphaGo to practice against previous iterations of itself 30 million times before facing the reigning human world champion. </span></p>
<p><span>&nbsp;</span></p>
<p dir="ltr">&nbsp;</p>
